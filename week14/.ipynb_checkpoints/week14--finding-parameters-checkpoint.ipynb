{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Math087 - Mathematical Modeling\n",
    "===============================\n",
    "[Tufts University](http://www.tufts.edu) -- [Department of Math](http://math.tufts.edu)  \n",
    "[George McNinch](http://gmcninch.math.tufts.edu) <george.mcninch@tufts.edu>  \n",
    "*Fall 2020*\n",
    "\n",
    "Course material (Week 14): Example(s) for \"finding model parameters\"\n",
    "----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "In these notes, I want to give examples of \"finding the parameters\" for some models, using empirical data.\n",
    "\n",
    "In particular, I want to revisit -- and extend in a few ways -- models we studied previously.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We considered the following:\n",
    "\n",
    "Financial market example\n",
    "=========================\n",
    "\n",
    "Consider the state of a financial market from week to week. \n",
    "\n",
    "- by a *bull market* we mean a week of generally rising prices. We are going to use the label ``L`` for *bull* market.\n",
    "- by a *bear market* we mean a week of genreally declining prices. We are going to use the label ``R`` for *bear* market.\n",
    "- by a *recession* we mean a general slowdown of the economy. We are going to use the label ``S`` for *recession*.\n",
    "\n",
    "We described the state using a Markov description -- let's recall that description."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "Let's number the weeks we are going to consider $k=0,1,2,...$.\n",
    "We can represent the probability that week $k$ is a bull market, a bear market, or in recession using a vector in $\\mathbb{R}^3$:\n",
    "\n",
    "$$\\mathbf{x}^{(k)} = \\begin{bmatrix}\n",
    "\\text{bull market prob.} \\\\\n",
    "\\text{bear market prob.} \\\\\n",
    "\\text{recession prob.}\n",
    "\\end{bmatrix}\n",
    "=\\begin{bmatrix}\n",
    "x_L \\\\\n",
    "x_R\\\\\n",
    "x_S\n",
    "\\end{bmatrix}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"216pt\" height=\"218pt\"\n",
       " viewBox=\"0.00 0.00 216.00 218.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 214)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-214 212,-214 212,4 -4,4\"/>\n",
       "<!-- L -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>L</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"118\" cy=\"-192\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"118\" y=\"-188.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">L</text>\n",
       "</g>\n",
       "<!-- L&#45;&gt;L -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>L&#45;&gt;L</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M142.5325,-199.752C153.5078,-200.4902 163,-197.9063 163,-192 163,-188.0317 158.7151,-185.5632 152.5743,-184.5944\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"152.6472,-181.0949 142.5325,-184.248 152.4059,-188.0908 152.6472,-181.0949\"/>\n",
       "<text text-anchor=\"middle\" x=\"181.5\" y=\"-188.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">p(L,L)</text>\n",
       "</g>\n",
       "<!-- R -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>R</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"27\" cy=\"-105\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"27\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">R</text>\n",
       "</g>\n",
       "<!-- L&#45;&gt;R -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>L&#45;&gt;R</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M91.3796,-187.9575C72.0124,-183.5431 46.849,-174.4599 33,-156 28.164,-149.5538 25.995,-141.3016 25.2126,-133.3223\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"28.7054,-133.043 24.8751,-123.1648 21.7092,-133.2756 28.7054,-133.043\"/>\n",
       "<text text-anchor=\"middle\" x=\"51.5\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">p(L,R)</text>\n",
       "</g>\n",
       "<!-- S -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>S</title>\n",
       "<ellipse fill=\"none\" stroke=\"#000000\" cx=\"118\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"118\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">S</text>\n",
       "</g>\n",
       "<!-- L&#45;&gt;S -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>L&#45;&gt;S</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M122.7673,-174.1838C124.0903,-168.4252 125.3433,-161.9824 126,-156 130.9466,-110.9374 130.9466,-99.0626 126,-54 125.7024,-51.2892 125.2824,-48.4839 124.789,-45.6906\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"128.202,-44.911 122.7673,-35.8162 121.3443,-46.3151 128.202,-44.911\"/>\n",
       "<text text-anchor=\"middle\" x=\"147\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">p(L,S)</text>\n",
       "</g>\n",
       "<!-- R&#45;&gt;L -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>R&#45;&gt;L</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M44.5617,-118.9105C52.5171,-125.4108 61.9271,-133.3829 70,-141 79.3025,-149.7773 89.0642,-159.9519 97.3373,-168.8937\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"94.8429,-171.3524 104.1753,-176.3681 100.0077,-166.6274 94.8429,-171.3524\"/>\n",
       "<text text-anchor=\"middle\" x=\"103.5\" y=\"-144.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">p(R,L)</text>\n",
       "</g>\n",
       "<!-- R&#45;&gt;R -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>R&#45;&gt;R</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M51.5325,-112.752C62.5078,-113.4902 72,-110.9063 72,-105 72,-101.0317 67.7151,-98.5632 61.5743,-97.5944\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"61.6472,-94.0949 51.5325,-97.248 61.4059,-101.0908 61.6472,-94.0949\"/>\n",
       "<text text-anchor=\"middle\" x=\"91\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">p(R,R)</text>\n",
       "</g>\n",
       "<!-- R&#45;&gt;S -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>R&#45;&gt;S</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M24.8751,-86.8352C24.6063,-76.2776 26.0448,-63.2709 33,-54 44.5769,-38.5687 64.0602,-29.6897 81.4548,-24.613\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"82.5766,-27.9381 91.3796,-22.0425 80.8214,-21.1617 82.5766,-27.9381\"/>\n",
       "<text text-anchor=\"middle\" x=\"51.5\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">p(R,S)</text>\n",
       "</g>\n",
       "<!-- S&#45;&gt;L -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>S&#45;&gt;L</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M133.641,-33.0377C145.9175,-46.0033 162.0549,-65.9192 169,-87 174.0065,-102.1965 174.0065,-107.8035 169,-123 163.3028,-140.2928 151.4201,-156.8018 140.5571,-169.3334\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"137.7644,-167.2028 133.641,-176.9623 142.9505,-171.9043 137.7644,-167.2028\"/>\n",
       "<text text-anchor=\"middle\" x=\"190\" y=\"-101.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">p(S,L)</text>\n",
       "</g>\n",
       "<!-- S&#45;&gt;R -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>S&#45;&gt;R</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M104.1753,-33.6319C94.8226,-43.9673 82.0275,-57.6516 70,-69 64.4499,-74.2368 58.2677,-79.6413 52.3608,-84.62\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"50.0238,-82.0112 44.5617,-91.0895 54.4929,-87.3988 50.0238,-82.0112\"/>\n",
       "<text text-anchor=\"middle\" x=\"103.5\" y=\"-57.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">p(S,R)</text>\n",
       "</g>\n",
       "<!-- S&#45;&gt;S -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>S&#45;&gt;S</title>\n",
       "<path fill=\"none\" stroke=\"#000000\" d=\"M142.5325,-25.752C153.5078,-26.4902 163,-23.9063 163,-18 163,-14.0317 158.7151,-11.5632 152.5743,-10.5944\"/>\n",
       "<polygon fill=\"#000000\" stroke=\"#000000\" points=\"152.6472,-7.0949 142.5325,-10.248 152.4059,-14.0908 152.6472,-7.0949\"/>\n",
       "<text text-anchor=\"middle\" x=\"180.5\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">p(S,S)</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7f2de82bbef0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from graphviz import Digraph\n",
    "\n",
    "h = Digraph()\n",
    "stats = [\"L\",\"R\",\"S\"]\n",
    "\n",
    "for s in stats:\n",
    "    h.node(s)\n",
    "    \n",
    "for s in stats:\n",
    "    for t in stats:\n",
    "        h.edge(s,t,f\"p({s},{t})\")\n",
    "h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "For $(x,y) \\in $ ``[\"L\",\"R\",\"S\"] x [\"L\",\"R\",\"S\"]`` the quantity $p(x,y)$ represents\n",
    "the probability that if the market is in state $x$ in week $t$ then the market is in state $y$ in week $t+1$.\n",
    "\n",
    "Thus, the matrix $P = (p(x,y))$ is the transition matrix for the Markov chain corresponding to the transition diagram displayed above.\n",
    "\n",
    "\n",
    "The probabilities evolve from week $k$ to week $k+1$ via the matrix\n",
    "\n",
    "$$P = \\begin{bmatrix}\n",
    "p(L,L) & p(R,L) & p(S,L) \\\\\n",
    "p(L,R) & p(R,R) & p(S,R) \\\\\n",
    "p(L,S) & p(R,S) & p(S,S) \n",
    "\\end{bmatrix};$$\n",
    "\n",
    "i.e. $$\\mathbf{x}_{k+1} = P \\cdot \\mathbf{x}_k.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Question 1\n",
    "==========\n",
    "\n",
    "How do we find the probabilities $p(x,y)$ for \n",
    "\n",
    "$(x,y) \\in $ ``[\"L\",\"R\",\"S\"] x [\"L\",\"R\",\"S\"]``?\n",
    "\n",
    "Well, let's suppose we are given weekly state data for the financial market in question. Thus\n",
    "we are given a list\n",
    "\n",
    "```\n",
    "FState = [ f0, f1, f2, f3, ... ]\n",
    "```\n",
    "\n",
    "where each ``FState[i] = fi`` $\\in$ ``[\"L\",\"R\",\"S\"]`` corresponds to the state during week ``i``.\n",
    "\n",
    "Let's consider the problem of finding the values\n",
    "\n",
    "$$p(L,L), \\quad p(L,R), \\quad p(L,S)$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "\n",
    "For this, we make a list ``IL`` of all indices ``i`` for which ``FState[i] == \"L\"``; let's write ``N`` for the length of the list ``FState``.\n",
    "\n",
    "Now from the point-of-view of the given data ``FState``, the probability ``p(L,L)`` is best approximated by the ratio \n",
    "\n",
    "(number of indices ``i`` $\\in$ ``IL`` for which ``FState[i+1] ==\"L\"``) / ``N``.\n",
    "\n",
    "Similarly, ``p(L,R)`` is best approximated by the ratio \n",
    "\n",
    "(number of indices ``i`` $\\in$ ``IL`` for which ``FState[i+1] ==\"R\"``) / ``N``. \n",
    "\n",
    "It should now be clear how each ``p(x,y)`` may be approximated from our empirical data.\n",
    "\n",
    "-----------\n",
    "\n",
    "Let's write a ``python`` function which takes as input a list ``FState`` and returns the $3 \\times 3$ matrix\n",
    "$P = (p(x,y))_{x,y}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "states = [\"L\",\"R\",\"S\"]\n",
    "\n",
    "def prob_from_data(fstate):\n",
    "    fstate_i = [(index,fstate[index]) for index in range(len(fstate))]\n",
    "    def test_state(j,state): \n",
    "        if j>=len(fstate):\n",
    "            return False\n",
    "        else: \n",
    "            return fstate[j]==state\n",
    "    def I(s):\n",
    "        ## e.g. I(\"R\") returns the list of indices i for which fstate[i]==\"R\"\n",
    "        return [index for (index,f) in fstate_i if f == s]\n",
    "    def J(s1,s2):\n",
    "        ## if I(s1) is non-empty, return the proportion of indices i in I(s1) \n",
    "        ## for which fstate[i+1] == s1\n",
    "        ## if I(s1) == [], return 1/3\n",
    "        II=I(s1)\n",
    "        if len(II)>0:\n",
    "            J=[index for index in II if test_state(index+1,s2)]\n",
    "            return 1.*len(J)/len(II)\n",
    "        else:\n",
    "            return 1./3    \n",
    "    # I[\"R\"] is the collection of all indices i for which fstate[i]==\"R\"\n",
    "    # J[\"R\"][\"S\"] is ratio: \n",
    "    #  #indices i for which fstate[i]==\"R\" & fstate[i+1]==\"S\"\n",
    "    # over length I[\"R\"]\n",
    "    return np.array([[J(s,t) for s in states] for t in states])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We now consider two data-sets, each for 500 weeks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[501, 501]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fstate1 = ['R', 'R', 'R', 'R', 'R', 'R', 'R', 'L', 'L', 'L', 'L', 'L',\n",
    "           'L', 'L', 'L', 'L', 'R', 'R', 'L', 'L', 'R', 'R', 'R', 'R',\n",
    "           'R', 'R', 'R', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'R', 'L',\n",
    "           'R', 'R', 'L', 'L', 'R', 'R', 'R', 'L', 'L', 'R', 'R', 'L',\n",
    "           'L', 'L', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'L', 'L',\n",
    "           'L', 'S', 'S', 'S', 'L', 'L', 'L', 'L', 'R', 'R', 'R', 'L',\n",
    "           'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L',\n",
    "           'L', 'L', 'L', 'L', 'L', 'L', 'L', 'R', 'R', 'R', 'R', 'R',\n",
    "           'S', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L',\n",
    "           'L', 'L', 'L', 'L', 'L', 'L', 'L', 'R', 'R', 'R', 'R', 'R',\n",
    "           'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
    "           'R', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L',\n",
    "           'L', 'L', 'L', 'L', 'S', 'R', 'R', 'R', 'L', 'L', 'L', 'L',\n",
    "           'L', 'L', 'L', 'R', 'S', 'S', 'R', 'R', 'S', 'S', 'R', 'R',\n",
    "           'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'S', 'S', 'S', 'L',\n",
    "           'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L',\n",
    "           'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'R', 'R', 'L', 'L',\n",
    "           'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L',\n",
    "           'L', 'R', 'R', 'R', 'R', 'L', 'L', 'L', 'R', 'R', 'R', 'S',\n",
    "           'S', 'S', 'S', 'S', 'L', 'R', 'S', 'S', 'S', 'L', 'L', 'L',\n",
    "           'L', 'L', 'S', 'S', 'S', 'S', 'L', 'L', 'L', 'L', 'L', 'L',\n",
    "           'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L',\n",
    "           'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L',\n",
    "           'L', 'L', 'L', 'L', 'L', 'L', 'R', 'R', 'R', 'R', 'R', 'R',\n",
    "           'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'L', 'L',\n",
    "           'L', 'L', 'R', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'R',\n",
    "           'R', 'L', 'L', 'S', 'L', 'R', 'R', 'R', 'R', 'L', 'L', 'L',\n",
    "           'L', 'L', 'L', 'L', 'L', 'R', 'R', 'L', 'L', 'L', 'L', 'L',\n",
    "           'R', 'L', 'L', 'L', 'R', 'R', 'R', 'R', 'L', 'L', 'L', 'L',\n",
    "           'L', 'L', 'L', 'L', 'S', 'S', 'L', 'L', 'L', 'L', 'L', 'L',\n",
    "           'L', 'S', 'R', 'R', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L',\n",
    "           'L', 'L', 'L', 'L', 'L', 'L', 'L', 'R', 'R', 'R', 'R', 'R',\n",
    "           'R', 'R', 'R', 'R', 'R', 'R', 'R', 'S', 'S', 'R', 'R', 'R',\n",
    "           'R', 'R', 'R', 'R', 'R', 'R', 'S', 'R', 'R', 'R', 'R', 'R',\n",
    "           'L', 'L', 'L', 'L', 'L', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
    "           'R', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L',\n",
    "           'L', 'L', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'S', 'L', 'L',\n",
    "           'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L',\n",
    "           'L', 'L', 'S', 'R', 'R', 'L', 'L', 'L', 'L', 'L', 'L', 'L',\n",
    "           'L', 'L', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'L',\n",
    "           'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'S', 'R', 'R', 'R',\n",
    "           'R', 'R', 'R', 'L', 'L', 'L', 'L', 'L', 'L']\n",
    "\n",
    "fstate2 = ['S', 'S', 'S', 'S', 'R', 'L', 'L', 'R', 'R', 'R', 'R', 'R',\n",
    "           'S', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L',\n",
    "           'L', 'L', 'L', 'L', 'L', 'R', 'R', 'L', 'L', 'L', 'L', 'R',\n",
    "           'R', 'R', 'R', 'R', 'L', 'L', 'L', 'L', 'L', 'R', 'L', 'L',\n",
    "           'L', 'L', 'L', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'L', 'L',\n",
    "           'L', 'L', 'L', 'L', 'L', 'R', 'S', 'L', 'L', 'L', 'L', 'L',\n",
    "           'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L',\n",
    "           'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L',\n",
    "           'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L',\n",
    "           'S', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L',\n",
    "           'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'R', 'R',\n",
    "           'R', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L',\n",
    "           'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L',\n",
    "           'L', 'L', 'L', 'R', 'L', 'L', 'L', 'L', 'R', 'R', 'R', 'S',\n",
    "           'S', 'S', 'S', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L',\n",
    "           'L', 'L', 'L', 'L', 'R', 'R', 'R', 'R', 'R', 'L', 'L', 'L',\n",
    "           'L', 'R', 'R', 'R', 'R', 'R', 'R', 'S', 'S', 'S', 'L', 'L',\n",
    "           'L', 'L', 'R', 'R', 'L', 'S', 'R', 'R', 'R', 'R', 'L', 'L',\n",
    "           'L', 'L', 'L', 'R', 'R', 'L', 'L', 'L', 'L', 'L', 'L', 'S',\n",
    "           'S', 'S', 'S', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'R', 'R',\n",
    "           'R', 'R', 'R', 'R', 'R', 'R', 'L', 'R', 'R', 'R', 'R', 'R',\n",
    "           'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L',\n",
    "           'L', 'L', 'L', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'S',\n",
    "           'L', 'L', 'L', 'S', 'S', 'S', 'L', 'L', 'L', 'L', 'L', 'L',\n",
    "           'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L',\n",
    "           'S', 'S', 'S', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L',\n",
    "           'L', 'L', 'L', 'L', 'L', 'L', 'R', 'R', 'R', 'R', 'R', 'S',\n",
    "           'S', 'L', 'L', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
    "           'R', 'R', 'L', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
    "           'R', 'R', 'L', 'L', 'L', 'R', 'R', 'R', 'R', 'R', 'R', 'R',\n",
    "           'S', 'L', 'R', 'R', 'R', 'S', 'S', 'S', 'S', 'S', 'S', 'S',\n",
    "           'L', 'L', 'L', 'L', 'L', 'L', 'L', 'R', 'R', 'R', 'L', 'L',\n",
    "           'L', 'R', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L',\n",
    "           'R', 'R', 'R', 'R', 'R', 'R', 'L', 'L', 'L', 'L', 'L', 'L',\n",
    "           'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L',\n",
    "           'L', 'L', 'L', 'L', 'L', 'L', 'R', 'R', 'R', 'R', 'R', 'R',\n",
    "           'S', 'L', 'L', 'L', 'L', 'L', 'R', 'R', 'L', 'L', 'L', 'L',\n",
    "           'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L',\n",
    "           'L', 'L', 'L', 'L', 'L', 'L', 'R', 'S', 'L', 'L', 'L', 'L',\n",
    "           'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L',\n",
    "           'L', 'L', 'L', 'S', 'S', 'S', 'S', 'R', 'R', 'R', 'R', 'R',\n",
    "           'R', 'R', 'L', 'L', 'L', 'L', 'L', 'L', 'L']\n",
    "\n",
    "\n",
    "[len(fstate1),len(fstate2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let's compute the probabilities for these two sets of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.881, 0.149, 0.265],\n",
       "        [0.089, 0.799, 0.235],\n",
       "        [0.027, 0.052, 0.5  ]]),\n",
       " array([[0.896, 0.152, 0.333],\n",
       "        [0.083, 0.773, 0.071],\n",
       "        [0.018, 0.076, 0.595]])]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(M1,M2)=map(prob_from_data,[fstate1,fstate2])\n",
    "[M1,M2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Question 2\n",
    "==========\n",
    "\n",
    "The empirical evidence in the above setting gives some credibility to our model -- two different data sets produced very similar matrices.\n",
    "\n",
    "On the other hand, suppose that we had reason to believe that market behavior depended on more than just the previous weeks behavior.\n",
    "\n",
    "There are of course other possible models. For example, perhaps taking into account the preceding two weeks does a better job of predicting  the market behavior?\n",
    "\n",
    "-----------------\n",
    "\n",
    "Let's consider what such a model might look like.\n",
    "\n",
    "If week $t$ was in state $x$ and week $t+1$ was in state $y$, then we'd like to compute the probabilities\n",
    "describing the possible states of week $t+2$.\n",
    "\n",
    "There are now 9 possibilities for $x,y$; let's order them in the following way:\n",
    "\n",
    "```\n",
    "[(\"L\",\"L\"),(\"L\",\"R\"),(\"L\",\"S\"),\n",
    " (\"R\",\"L\"),(\"R\",\"R\"),(\"R\",\"S\"),\n",
    " (\"S\",\"L\"),(\"S\",\"R\"),(\"S\",\"S\")]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We write $p(x,y,z)$ for the probability that week $t+2$ is in state $z$ given that week $t$ was in state $x$ and week $t+1$ was in state $y$.\n",
    "\n",
    "This leads to a $3 \\times 9$ matrix $Q$, which we can compute from our state data using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "statepairs=[(\"L\",\"L\"),(\"L\",\"R\"),(\"L\",\"S\"),\n",
    "            (\"R\",\"L\"),(\"R\",\"R\"),(\"R\",\"S\"),\n",
    "            (\"S\",\"L\"),(\"S\",\"R\"),(\"S\",\"S\")]\n",
    "\n",
    "def prob_from_data_two(fstate):\n",
    "    def test_state(j,state): \n",
    "        if j>=len(fstate):\n",
    "            return False\n",
    "        else: \n",
    "            return fstate[j]==state\n",
    "    def I(s,t):\n",
    "        ## e.g. I(\"R\",\"S\") returns the list of indices i for which fstate[i]==\"R\"\n",
    "        ## and fstate[i+1]==\"S\"\n",
    "        N=len(fstate)\n",
    "        return [index for index in range(N-2) if fstate[index] == s and fstate[index+1]==t]\n",
    "    def J(s1,s2,s3):\n",
    "        ## if I(s1) is non-empty, return the proportion of indices i in I(s1) \n",
    "        ## for which fstate[i+1] == s1\n",
    "        ## if I(s1) == [], return 1/3\n",
    "        II=I(s1,s2)\n",
    "        if len(II)>0:\n",
    "            J=[index for index in II if test_state(index+2,s3)]\n",
    "            return 1.*len(J)/len(II)\n",
    "        else:\n",
    "            return 1./3    \n",
    "    # I[\"R\"] is the collection of all indices i for which fstate[i]==\"R\"\n",
    "    # J[\"R\"][\"S\"] is ratio: \n",
    "    #  #indices i for which fstate[i]==\"R\" & fstate[i+1]==\"S\"\n",
    "    # over length I[\"R\"]\n",
    "    return np.array([[J(s,t,u) for (s,t) in statepairs] for u in states])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create the matrices\n",
    "\n",
    "(N1,N2) = map(prob_from_data_two,[fstate1,fstate2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check that the matrices are stochastic\n",
    "## this code will do nothing if things are OK, and raise an \"exception\" if not\n",
    "\n",
    "def test_stoch(M):\n",
    "    np.testing.assert_almost_equal(np.ones(3)@M,np.ones(9))\n",
    "    \n",
    "for N in [N1,N2]:\n",
    "    test_stoch(N)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.879 0.115 0.125 0.962 0.165 0.222 0.778 0.    0.353]\n",
      " [0.089 0.808 0.5   0.038 0.784 0.111 0.222 1.    0.176]\n",
      " [0.031 0.077 0.375 0.    0.05  0.667 0.    0.    0.471]]\n",
      "\n",
      "[[0.901 0.111 0.167 0.85  0.157 0.6   0.929 0.333 0.28 ]\n",
      " [0.082 0.815 0.167 0.1   0.765 0.    0.071 0.667 0.08 ]\n",
      " [0.017 0.074 0.667 0.05  0.078 0.4   0.    0.    0.64 ]]\n"
     ]
    }
   ],
   "source": [
    "## print \n",
    "\n",
    "print(\"\\n\\n\".join([f\"{N1}\",\n",
    "                   f\"{N2}\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "How to implement \"prediction\" with this method?\n",
    "===============================================\n",
    "\n",
    "Note that for a $3 \\times 9$ matrix $M$, we can't compute *powers* $M^j$ -- the product $M \\cdot M$ isn't defined!\n",
    "\n",
    "In order to find the probabilities for a give week, we need to know the state of the preceding two weeks.\n",
    "\n",
    "It is pretty easy to writea ``python`` function to produce a *simulation* of the behavior of the market.\n",
    "\n",
    "\n",
    "So we'll implement \n",
    "```\n",
    "def Next(prob,history):\n",
    "```\n",
    "where we need to have\n",
    "\n",
    "```\n",
    "probe.shape == (3,9)\n",
    "len(history) >= 2\n",
    "```\n",
    "\n",
    "and\n",
    "\n",
    "```\n",
    "history = [...,x1,x0]\n",
    "```\n",
    "where ``x1,x0`` $\\in$ ``[\"L\",\"R\",\"S\"]``\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from numpy.random import default_rng\n",
    "\n",
    "rng = default_rng()\n",
    "\n",
    "states = [\"L\",\"R\",\"S\"]\n",
    "\n",
    "statepairs=[(\"L\",\"L\"),(\"L\",\"R\"),(\"L\",\"S\"),\n",
    "            (\"R\",\"L\"),(\"R\",\"R\"),(\"R\",\"S\"),\n",
    "            (\"S\",\"L\"),(\"S\",\"R\"),(\"S\",\"S\")]\n",
    "\n",
    "def sbv(index,size):\n",
    "    return np.array([1.0 if i == index else 0.0 for i in range(size)])\n",
    "\n",
    "def Next(prob,history):\n",
    "        (x1,x0) = history[-2:]\n",
    "        i = statepairs.index((x1,x0))\n",
    "        return prob[:,i]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['R', 'L', 'L', 'S', 'R', 'R', 'R', 'R', 'L', 'L', 'L', 'L', 'R', 'L', 'L', 'L', 'L', 'L', 'L', 'R', 'S', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'R', 'L', 'L', 'L', 'L', 'L', 'R', 'R', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'S', 'S', 'S', 'S', 'R', 'R', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'R', 'R', 'R', 'R', 'R', 'R', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'R', 'R', 'R', 'R', 'R', 'R', 'L', 'L', 'L', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'L', 'L', 'L', 'L', 'R', 'S', 'S', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'L', 'R', 'R', 'R', 'R', 'S', 'S', 'S', 'S', 'L', 'L', 'L', 'L', 'L', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'L', 'S', 'S', 'S', 'L', 'L', 'L', 'S', 'L', 'L', 'S', 'R', 'R', 'L', 'L', 'S', 'L', 'L', 'L', 'R', 'R', 'L', 'L', 'L', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'R', 'L', 'R', 'R', 'R']\n"
     ]
    }
   ],
   "source": [
    "def gen_next(prob,history):\n",
    "    return rng.choice(states,p=Next(prob,history))\n",
    "\n",
    "def gen(prob,num):\n",
    "    hist = [rng.choice(states),rng.choice(states)]\n",
    "    for i in range(num):\n",
    "        hist.append(gen_next(prob,hist[-2:]))\n",
    "    return hist    \n",
    "    \n",
    "l=gen(N1,250)\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "More interesting would be to produce the probability vector for a given week, given \n",
    "a $3 \\times 9$ matrix together with a history list of *probability vectors*.\n",
    "\n",
    "This would permit us to consider the question: does the probability vector approach an equilibrium state (as it does in the single-week case by the "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Assessment?\n",
    "==========\n",
    "\n",
    "The results of ``prob_from_data`` and ``prob_from_data_two`` are essentially tables of probabilities.\n",
    "\n",
    "A possible measure of the effectiveness of our model(s) is: to what extent do different data sets result in similar\n",
    "probability descriptions?\n",
    "\n",
    "We can compute the squared norm (magnitude) of a matrix by flattening it into a vector and computing\n",
    "the sum of the squares of its coefficients.  In ``python``, this flattening can be performed\n",
    "by calling ``nd.ndarray.flatten(...)``\n",
    "\n",
    "We compare the matrices obtained from the two data sets by using the squared norm (in this \"flattened sense\") of their difference. \n",
    "\n",
    "We also divide by the number of coefficients; note that for $\\mathbf{v},\\mathbf{w} \\in \\mathbb{R}^n$, the quantity $\\dfrac{1}{n}\\Vert \\mathbf{v} - \\mathbf{w}\\Vert^2$ is the\n",
    "average of the differences $(v_i-w_i)^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.004694907068603097, 0.02799503444124507]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def norm_sq(v):\n",
    "    return v@v\n",
    "\n",
    "def mat_norm_sq(M):\n",
    "    return norm_sq(np.ndarray.flatten(M))\n",
    "\n",
    "## recall that M1 and M2 were the probabilities for the respective \n",
    "## data sets, based on previous week\n",
    "\n",
    "e1=mat_norm_sq(M1-M2)/9\n",
    "e2=mat_norm_sq(N1-N2)/27\n",
    "[e1,e2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "From this computation, it appears that -- for the datea ``fstate1``and ``fstate2`` -- the model \"the state of the financial market is predicted by the state of the prior week\" does a better job than the second model (\"the state is predicted by the prior two weeks\")."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Recall some optimization problems:\n",
    "==================================\n",
    "\n",
    "- oil spill cleanup (week 1)\n",
    "- television manufacturing (week 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
