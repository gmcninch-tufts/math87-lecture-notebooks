{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Math087 - Mathematical Modeling\n",
    "===============================\n",
    "[Tufts University](http://www.tufts.edu) -- [Department of Math](http://math.tufts.edu)  \n",
    "[George McNinch](http://gmcninch.math.tufts.edu) <george.mcninch@tufts.edu>  \n",
    "*Fall 2020*\n",
    "\n",
    "Course material (Week 2): Root Finding\n",
    "--------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are often interesting in finding solutions to (non-linear) equations $ğ‘“(ğ‘¥)=0$.\n",
    "\n",
    "Here we describe various methods for finding such solutions under assumptions and requirements.\n",
    "\n",
    "\n",
    "By a root of $ğ‘“$, we just mean a real number $ğ‘¥_0$ such that $ğ‘“(ğ‘¥_0)=0$.\n",
    "\n",
    "Of course, for some very special functions $ğ‘“$, we have formulas for roots. For example, if $ğ‘“$ is a quadratic polynomial, say $ğ‘“(ğ‘¥)=ğ‘ğ‘¥^2+ğ‘ğ‘¥+ğ‘$ for real numbers $ğ‘,ğ‘,ğ‘$, then there are in general two roots, given by the *quadratic formula*\n",
    "$$ğ‘¥_0=\\dfrac{âˆ’ğ‘Â±\\sqrt{ğ‘^2âˆ’4ğ‘ğ‘}}{2ğ‘}.$$\n",
    "(Of course, these roots are only real numbers in case of $ğ‘^2âˆ’4 ğ‘ ğ‘ \\ge 0$). But such a formula is far too much to ask for, in general!\n",
    "\n",
    "We describe here algorithmic methods for approximating roots of \"nice enough\" functions which are less precise but more generally applicable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bisection - overview\n",
    "=====================\n",
    "\n",
    "The bisection algorithm permits one to approximate a root of a continuous function $ğ‘“$, provided that one knows points $ğ‘¥_ğ¿<ğ‘¥_ğ‘…$ in the domain of $ğ‘“$ for which the function values $ğ‘“(ğ‘¥_ğ¿)$ and $ğ‘“(ğ‘¥_ğ‘…)$ are non-zero and have opposite signs. The algorithm then returns an approximate root in the interval $(ğ‘¥_ğ¿,ğ‘¥_ğ‘…)$.\n",
    "\n",
    "Of course, for a continuous $ğ‘“$ the *intermediate value theorem* implies that there is at least one root $ğ‘¥_0$ of $ğ‘“$ in the interval $(ğ‘¥ğ¿,ğ‘¥ğ‘…)$.\n",
    "\n",
    "To find a root, the algorithm iteratively divides the interval $[ğ‘¥_ğ¿,ğ‘¥_ğ‘…]$\n",
    "into two sub-intervals by introducing the midpoint $ğ‘¥_ğ¶=\\dfrac{ğ‘¥_ğ¿+ğ‘¥_ğ‘…}{2}$. It examines the signs of the values $ğ‘“(ğ‘¥_ğ¿)$, $ğ‘“(ğ‘¥_ğ¶)$ and $ğ‘“(ğ‘¥_ğ‘…)$ and discards the interval on which the sign doesn't change. (Of course, if $ğ‘“(ğ‘¥_ğ¶)$\n",
    "happens to be zero, that is the root!)\n",
    "\n",
    "So for example, if $ğ‘“(ğ‘¥_ğ¿)$ and $ğ‘“(ğ‘¥_ğ¶)$ differ in sign, the procedure is repeated on this smaller interval $[ğ‘¥_ğ¿,ğ‘¥_ğ¶]$.\n",
    "\n",
    "One way of looking at the \"theory\" underlying the use of this algorithm is the following: writing $x_N$ for the approximate solution returned by the algorithm\n",
    "after $N$ iterations, one knows that the limit $$\\lim_{N \\to \\infty}\n",
    "x_N$$ exists and is a solution to $f(x) = 0$ -- in words: the estimates converge to a solution.\n",
    "\n",
    "\n",
    "\n",
    "The ``python`` library ``scipy`` has an [implementation\n",
    "of the bisection algorithm](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.bisect.html#scipy.optimize.bisect), which we can use.\n",
    "\n",
    "This implementation is found in the ``scipy.optimization`` library, and the function has the following specification:\n",
    "\n",
    "```{python}\n",
    "scipy.optimize.bisect(f,a,b,args=(), \n",
    "                      xtol=2e-12, \n",
    "                      rtol=8.881784197001252e-16, \n",
    "                      maxiter=100, \n",
    "                      full_output=False, \n",
    "                      disp=True)\n",
    "```\n",
    "\n",
    "Here ``f`` is the function in question, and ``a`` and ``b`` are the values bracketing some root of ``f``.\n",
    "\n",
    "Morally, the argument ``rtol`` indicates the desired tolerance  -- thus the function should return a value ``x`` for which ``|f(x)| < rtol``. In practice, things are a bit more complicated (read the docs when required...!)\n",
    "\n",
    "Also:\n",
    "> If convergence is not achieved in ``maxiter`` iterations, an error is raised. Must be >= 0.\n",
    "\n",
    "Example\n",
    "-------\n",
    "For example, we can use â€˜bisectâ€˜ to approximate the roots of \\\\(f(x) = x^2 - x -1\\\\). \n",
    "Recall that those roots are\n",
    "\\\\[\\dfrac{1 \\pm \\sqrt{5}}{2}\\\\]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bisection solutions: [ 1.61803399 -0.61803399]\n",
      "via radicals:        [ 1.61803399 -0.61803399]\n",
      "difference:          [-1.17417187e-12  1.17417187e-12]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import bisect\n",
    "\n",
    "def f(x):\n",
    "    return x**2 - x - 1\n",
    "\n",
    "## lets make a list of the solutions\n",
    "\n",
    "approx_sol = np.array([bisect(f,1,2),\n",
    "                       bisect(f,-2,0)])\n",
    "\n",
    "sol_via_radicals = np.array([(1+np.sqrt(5))/2,\n",
    "                             (1-np.sqrt(5))/2 ])\n",
    "\n",
    "report = \"\\n\".join([f\"bisection solutions: {approx_sol}\",\n",
    "                    f\"via radicals:        {sol_via_radicals}\",\n",
    "                    f\"difference:          {approx_sol-sol_via_radicals}\"])\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: what does this ``bisect``function do if ``f(a)`` and ``f(b)`` have the same sign?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example\n",
    "-------\n",
    "We can estimate zeros of the \\\\(\\sin\\\\) function - here we get an approximation to \\\\(\\pi\\\\), since we happen to know that $\\sin(1) >0$, $\\sin(4)<0$, and $\\pi$ is the unique root of $\\sin(x)=0$ between $1$ and $4$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1415926535887593"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def g(x): return np.sin(x)\n",
    "\n",
    "bisect(g,1,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: How does this solution compare with the value of pi stored by ``numpy``?\n",
    "    \n",
    "(Compare with ``np.pi``)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example \n",
    "-------\n",
    "And we can estimate the transcendental number \\\\(e = \\exp(1)\\\\) e.g. by finding roots of the function \\\\(f(x) = 1 - \\ln(x)\\\\): \n",
    "\n",
    "(**Question**: try comparing the answer with ``np.exp(1)``)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.7182818284582027"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def h(x):\n",
    "    return 1 - np.log(x)\n",
    "\n",
    "bisect(h,1,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some slightly more sophisticated methods of approximating roots:\n",
    "\n",
    "Secant Method\n",
    "=============\n",
    "\n",
    "[You can read the wikipedia description](https://en.wikipedia.org/wiki/Secant_method) of the secant method here.\n",
    "\n",
    "> The secant method is a root-finding algorithm that uses a succession of roots of secant lines to better approximate a root of a function f.\n",
    "\n",
    "Newton's method\n",
    "===============\n",
    "\n",
    "[And here is the wikipedia description of Newton's method](https://en.wikipedia.org/wiki/Newton%27s_method).\n",
    "\n",
    "> it is a root-finding algorithm which produces successively better approximations to the roots (or zeroes) of a real-valued function. The most basic version starts with a single-variable function $f$ defined for a real variable $x$, the function's derivative $f'$, and an initial guess $x_0$ for a root of $f$.\n",
    "\n",
    "Let's quickly summarize the simplest form of Newton's method:\n",
    "\n",
    "If the function is sufficiently \"nice\" and if the initial guess $x_0$ is close enough to a root, then\n",
    "\n",
    "$$x_1 = x_0 âˆ’ \\dfrac{f(x_0)}{f'(x_0)}$$\n",
    "\n",
    "\n",
    "is a better approximation of the root than $x_0$. Notice that $x_1$ is the $x$-coordinate of the point of intersection of the $x$-axis with the tangent line to $f$ at $(x_0,f(x_0)$.\n",
    "\n",
    "The process is then iterated: for $n \\ge 2$, we set\n",
    "$$x_n = x_{n-1} - \\dfrac{f(x_{n-1})}{f'(x_{n-1})}.$$\n",
    "\n",
    "Under favorable circumstances, $\\lim_{n \\to \\infty} x_n$ is a root of $f$.\n",
    "\n",
    "The ``scipy`` library makes both the secant method and Newton's method available via \n",
    "[scipy.optimize.newton](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.newton.html)\n",
    "\n",
    "```{python}\n",
    "scipy.optimize.newton(func, x0, \n",
    "                      fprime=None, \n",
    "                      args=(), \n",
    "                      tol=1.48e-08, \n",
    "                      maxiter=50, \n",
    "                      fprime2=None, \n",
    "                      x1=None, \n",
    "                      rtol=0.0, \n",
    "                      full_output=False, \n",
    "                      disp=True)\n",
    "```\n",
    "\n",
    "The mandatory arguments to this function are ``func`` and the initial guess ``x0``.\n",
    "If the derivative ``fprime`` is given, this function uses Newton's method to approximate a root. \n",
    "\n",
    "If the value of ``fprime2`` is ``None`` - the default value -- then this function uses either Newton's method or the secant method to approximate a root of $f$. (If a second derivative ``fprime2`` is given, then [Halley's method](https://en.wikipedia.org/wiki/Halley%27s_method) is used).\n",
    "\n",
    "Assuming ``fprime2 = None``, \n",
    "whether to use Newton's method or the secant method is determined\n",
    "by the value of ``fprime``.\n",
    "\n",
    "If the value of ``fprime`` is ``None`` (the default value), then this function uses the secant method to approximate a root of $f$. It then requires a value other than ``None`` for the ``x1`` argument (since the secant method requires *two* initial values).\n",
    "\n",
    "If ``fprime`` is given, this function uses Newton's method to approximate a root.\n",
    "\n",
    "------------\n",
    "\n",
    "Let's repeat the preceding examples:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example\n",
    "-------\n",
    "\n",
    "- $f(x) = x^2 - x -1$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "secant [1.618033988749909, -0.6180339887498949]\n",
      "newton [1.618033988749895, -0.6180339887498948]\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import newton\n",
    "\n",
    "def f(x):\n",
    "    return x**2 - x - 1\n",
    "\n",
    "## secant method\n",
    "sec=[newton(f,1,x1=2),newton(f,-1,x1=-2)]\n",
    "\n",
    "## Newton's method\n",
    "def fprime(x):\n",
    "    return 2*x - 1\n",
    "\n",
    "newt=[newton(f,1,fprime),newton(f,-1,fprime)]\n",
    "\n",
    "report = \"\\n\".join([f\"secant {sec}\",\n",
    "                    f\"newton {newt}\",])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example\n",
    "-------\n",
    "\n",
    "$\\pi$ via $\\sin$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "secant: 3.141592653589793\n",
      "newton: 3.141592653589793\n"
     ]
    }
   ],
   "source": [
    "## use the secant method with x0 = 1 and x1 = 4\n",
    "sec_pi = newton(np.sin,1.0,x1=4.0)\n",
    "\n",
    "## use newton's method with x0=1\n",
    "newt_pi = newton(np.sin,2,fprime=np.cos)\n",
    "\n",
    "report = \"\\n\".join([f\"secant: {sec_pi}\",\n",
    "                    f\"newton: {newt_pi}\"])\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example:\n",
    "--------\n",
    "\n",
    "$e$ via $h(x) = 1  - \\ln(x)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "secant: 2.718281828459045\n",
      "newton: 2.718281828459045\n"
     ]
    }
   ],
   "source": [
    "def h(x):\n",
    "    return 1 - np.log(x)\n",
    "\n",
    "def hprime(x):\n",
    "    return -1/x\n",
    "\n",
    "e_secant = newton(h,2,x1=3)\n",
    "e_newt   = newton(h,3,fprime=hprime)\n",
    "\n",
    "\n",
    "report = \"\\n\".join([f\"secant: {e_secant}\",\n",
    "                    f\"newton: {e_newt}\"])\n",
    "\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**: what was the role of $x_0$ and $x_1$ in the above secant method examples? and what was the role of $x_0$ in the above newton-method examples?\n",
    "\n",
    "See what happens when you vary $x_0$ in the computation of ``newt_pi`` above.\n",
    "\n",
    "See what happens when you give ``newton`` an incorrect first derivative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modeling example\n",
    "=================\n",
    "\n",
    "A large population of $N$ people need to be tested for a disease. In order to reduce the costs of\n",
    "testing, a grouping strategy is proposed: Take blood samples from each person in a group of $x$\n",
    "people. Divide each sample in half and mix one-half of each personâ€™s sample into one mixture. Test\n",
    "the mixture. If it is negative, then we know that all $x$ people in the group are negative. If it is positive, then at least one person in that group is positive, so test the other half of each personâ€™s sample. What value of $x$ minimizes the total number of tests that needs to be done?\n",
    "\n",
    "Variables:\n",
    "- $N$ = total population\n",
    "- $x$ = group size\n",
    "- $q$ = probability of one individual testing negative\n",
    "- $T$ = total number of tests\n",
    "- $T_g$ = total number of group tests\n",
    "- $T_i$ = expected number of individual tests\n",
    "- $T = T_g + T_i$\n",
    "\n",
    "The number of group tests is just the population/group size, $T_g = N/x$.\n",
    "\n",
    "For $T_i$ we have $N/x$ groups of $x$ people and the probability of all people in the group being negative is $q^x$. Thus, the probability of one person in the group testing positive is $1 âˆ’ q^x$.\n",
    "If this happens, we have to do x tests! So...\n",
    "\n",
    "$$T_i = \\dfrac{N}{x}\\left[(1-q^x)x \\right] = N\\left(1-q^x\\right).$$\n",
    "and thus\n",
    "$$T = T_i + T_g = \\dfrac{N}{x} + N(1-q^x) = N(\\dfrac{1}{x} + 1 - q^x).$$\n",
    "\n",
    "To find the value of $x$ that yields the minimum number of required tests, we need to solve\n",
    "the equation $\\dfrac{dT}{dx} = 0$.\n",
    "\n",
    "Well,\n",
    "$$\\dfrac{dT}{dx} = N\\left(\\dfrac{-1}{x^2} - q^x \\ln q\\right).$$\n",
    "\n",
    "Since $q$ represents a *probability*, we have $0<q<1$. In particular, $\\ln(q) < 0$. Thus\n",
    "in order that $\\dfrac{dT}{dx} = 0$. we must have\n",
    "$$g(x) = \\dfrac{-1}{x^2} - (\\ln q)q^x = 0.$$\n",
    "\n",
    "It is not easy to directly solve the equation $g(x) = 0$. So we will apply Newton's method.\n",
    "For this, we need to know $g'(x)$ as well; it is\n",
    "\n",
    "$$g'(x) = \\dfrac{2}{x^3} - (\\ln q)^2 q^x.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.7, 2.719531322598942),\n",
       " (0.8, 2.9381695580526563),\n",
       " (0.9, 3.7545775568830564),\n",
       " (0.95, 5.02238523178711),\n",
       " (0.99, 10.516237295014893),\n",
       " (0.999, 32.12707425945638),\n",
       " (0.9999, 100.5012836847976)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from functools import partial \n",
    "\n",
    "def g(q,x):\n",
    "    return (-1/x**2) - np.log(q)* q**x\n",
    "\n",
    "def gprime(q,x):\n",
    "    return 2/x**3 - (np.log(q))**2 * q**x\n",
    "\n",
    "q_values = [0.7, 0.8, 0.9, 0.95, 0.99, 0.999, 0.9999]\n",
    "\n",
    "## note that partial(g,q) returns the function given by h(x) = g(q,x)\n",
    "## in other words, we \"partially evaluate\" the function g(q,x) to get a function \n",
    "## only of x.\n",
    "\n",
    "def newt(q): \n",
    "    return newton(partial(g,q),2,fprime=partial(gprime,q))\n",
    "\n",
    "# the following code returns a list of pairs (q,newt(q))\n",
    "# where q runs through the list q_values.\n",
    "# Here, newt(q) is the solution to g(q,x) = 0 obtained from Newton's method\n",
    "# (with x0 = 2).\n",
    "\n",
    "list(map(lambda x: (x,newt(x)),q_values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
